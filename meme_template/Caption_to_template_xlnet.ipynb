{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Caption_to_template_xlnet.ipynb","provenance":[{"file_id":"1XjzG874ByeoKUivtopqzqD84SseCHHD3","timestamp":1604778866884},{"file_id":"1a3bub7xQXZ4d9I9I3aBSMhpB2vHnFgkO","timestamp":1604292881556}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ab9e3e9dfa804be193023d8cb842e27e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a24953540ee45aeb99f6e7e5492b584","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_37e3f4d646064f2b9fc1ce43b03e21a4","IPY_MODEL_e6a04e4d83ef4252b6428a0a5cd7195f"]}},"4a24953540ee45aeb99f6e7e5492b584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37e3f4d646064f2b9fc1ce43b03e21a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_71cefe6387064158a57c5b3af0f4f454","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34ffb6af6aa149d2bc205035d73eb85d"}},"e6a04e4d83ef4252b6428a0a5cd7195f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f3db614c47644fef83ac70cb8c5b1f70","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/3 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1085ae48ce7c48b8984d09feaf10e9bc"}},"71cefe6387064158a57c5b3af0f4f454":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34ffb6af6aa149d2bc205035d73eb85d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f3db614c47644fef83ac70cb8c5b1f70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1085ae48ce7c48b8984d09feaf10e9bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"syXqOBRAwASC","executionInfo":{"status":"ok","timestamp":1604799979937,"user_tz":480,"elapsed":3888,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"6bc70f0e-44f9-46af-cc4a-0e318bffcd3b","colab":{"base_uri":"https://localhost:8080/"}},"source":["import torch\n","import random\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Poh7Q92AwDRY","executionInfo":{"status":"ok","timestamp":1604799983114,"user_tz":480,"elapsed":7059,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"dd3da494-f9d3-42cb-b986-eaa79522a751","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wLXKxpXJSuZN","executionInfo":{"status":"ok","timestamp":1604799983115,"user_tz":480,"elapsed":7053,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"fd86a217-b2df-4a2e-c014-cb537a6cf21f","colab":{"base_uri":"https://localhost:8080/"}},"source":["#@markdown Utility function (run on each Runtime restart)\n","\n","from IPython.display import clear_output\n","import os\n","import sys\n","\n","def download_from_gdrive(gdrive_id, filename):\n","    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$gdrive_id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$gdrive_id -O $filename && rm -rf /tmp/cookies.txt\n","\n","import torch\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('DEVICE:', DEVICE)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["DEVICE: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-fvoBiv1S0Te","executionInfo":{"status":"ok","timestamp":1604799983115,"user_tz":480,"elapsed":7047,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["DATA_DIR = 'memes900k'\n","CAPTIONS_FILE = os.path.join(DATA_DIR, 'captions.txt')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"R1C7z_lbTRyO","executionInfo":{"status":"ok","timestamp":1604799984085,"user_tz":480,"elapsed":8014,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["#@markdown Load and process the file with data and checkpoints Google Drive IDs\n","\n","GDRIVE_ID = '1S4QwcuznRxLlxkIT0Lb6vIuqDTib41B3'\n","FILE_IDS_NAME = 'file_ids.txt'\n","\n","download_from_gdrive(GDRIVE_ID, FILE_IDS_NAME)\n","\n","FILE_IDS = {}\n","with open(FILE_IDS_NAME, 'r') as f:\n","    for line in f:\n","        name, gid = line.strip().split('\\t')\n","        FILE_IDS[name] = gid\n","\n","clear_output()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"geTsncqzSzX5","executionInfo":{"status":"ok","timestamp":1604799986798,"user_tz":480,"elapsed":10723,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["#@title Load dataset\n","\n","# full dataset\n","print('Loading the dataset from Google Drive')\n","fname = f'{DATA_DIR}.zip'\n","download_from_gdrive(FILE_IDS[fname], fname)\n","!unzip -o {DATA_DIR}\n","clear_output()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"hA4eENI5X83Q","executionInfo":{"status":"ok","timestamp":1604799986799,"user_tz":480,"elapsed":10720,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ats0G4-bxCOf","executionInfo":{"status":"ok","timestamp":1604799991114,"user_tz":480,"elapsed":15031,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["from __future__ import absolute_import, division, print_function\n","\n","import glob\n","import logging\n","import os\n","import random\n","import json\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","import random\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm_notebook, trange\n","\n","\n","from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n","                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n","                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n","                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n","\n","from pytorch_transformers import AdamW, WarmupLinearSchedule\n","\n","\n","\n","logging.basicConfig(level=logging.INFO)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ3B5sy9YhBC","executionInfo":{"status":"ok","timestamp":1604799991114,"user_tz":480,"elapsed":15028,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["args = {\n","    'data_dir': 'memes900k/',\n","    'model_type':  'xlnet',\n","    'model_name': 'xlnet-base-cased',\n","    'task_name': 'binary',\n","    'output_dir': 'outputs/',\n","    'cache_dir': 'cache/',\n","    'do_train': True,\n","    'do_eval': True,\n","    'fp16': False,\n","    'fp16_opt_level': 'O1',\n","    'max_seq_length': 20,\n","    'output_mode': 'classification',\n","    'train_batch_size': 8,\n","    'eval_batch_size': 8,\n","\n","    'gradient_accumulation_steps': 1,\n","    'num_train_epochs': 1,\n","    'weight_decay': 0,\n","    'learning_rate': 4e-5,\n","    'adam_epsilon': 1e-8,\n","    'warmup_steps': 0,\n","    'max_grad_norm': 1.0,\n","\n","    'logging_steps': 50,\n","    'evaluate_during_training': False,\n","    'save_steps': 2000,\n","    'eval_all_checkpoints': True,\n","\n","    'overwrite_output_dir': False,\n","    'reprocess_input_data': False,\n","    \n","}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNf2MbaKYnwh","executionInfo":{"status":"ok","timestamp":1604799991115,"user_tz":480,"elapsed":15027,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["with open('args.json', 'w') as f:\n","    json.dump(args, f)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rY0lrcgnYqT5","executionInfo":{"status":"ok","timestamp":1604799991115,"user_tz":480,"elapsed":15024,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["MODEL_CLASSES = {\n","    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n","    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n","    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n","}\n","\n","config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsVCIcZSYvbC","executionInfo":{"status":"ok","timestamp":1604799991116,"user_tz":480,"elapsed":15020,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"240af5f5-e249-4c81-c2ef-c25524cee787","colab":{"base_uri":"https://localhost:8080/"}},"source":["config = config_class.from_pretrained(args['model_name'], num_labels=300)\n","tokenizer = tokenizer_class.from_pretrained(args['model_name'],num_labels=300)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `mem_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UwSe7zrecjB6","executionInfo":{"status":"ok","timestamp":1604799991116,"user_tz":480,"elapsed":15016,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"bab21007-6c27-4fd3-c5da-ff5cdf29067f","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(model_class)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["<class 'transformers.modeling_xlnet.XLNetForSequenceClassification'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wEZZUgHwYzRg","executionInfo":{"status":"ok","timestamp":1604800007677,"user_tz":480,"elapsed":31572,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"4e9125ff-2e90-4904-8271-2cd0fb063042","colab":{"base_uri":"https://localhost:8080/"}},"source":["model =  XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',num_labels=300)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `mem_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n","  FutureWarning,\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HKWuWAktbw2D","executionInfo":{"status":"ok","timestamp":1604800007678,"user_tz":480,"elapsed":31569,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["def prepare_features(seq_1, max_seq_length = 20, \n","             zero_pad = True, include_CLS_token = True, include_SEP_token = True):\n","    ## Tokenzine Input\n","    tokens_a = tokenizer.tokenize(seq_1)\n","   \n","    ## Truncate\n","    if len(tokens_a) > max_seq_length - 2:\n","        tokens_a = tokens_a[0:(max_seq_length - 2)]\n","    ## Initialize Tokens\n","    tokens = []\n","    if include_CLS_token:\n","        tokens.append(tokenizer.cls_token)\n","    ## Add Tokens and separators\n","    for token in tokens_a:\n","        tokens.append(token)\n","\n","    if include_SEP_token:\n","        tokens.append(tokenizer.sep_token)\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    ## Input Mask \n","    input_mask = [1] * len(input_ids)\n","    ## Zero-pad sequence lenght\n","    if zero_pad:\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","  \n","    return torch.tensor(input_ids).unsqueeze(0), input_mask"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DimPqkgdf6g","executionInfo":{"status":"ok","timestamp":1604800007679,"user_tz":480,"elapsed":31567,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"fc61efae-e511-4771-a072-31d2bb822869","colab":{"base_uri":"https://localhost:8080/"}},"source":["msg = \"My dog is cute!\"\n","print(prepare_features(msg)[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([[    3,   631,  2288,    27, 10920,   136,     4,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hAbp3jFW0L5t"},"source":["# Data preprocessing"]},{"cell_type":"code","metadata":{"id":"j77a7anJ13MZ","executionInfo":{"status":"ok","timestamp":1604800008721,"user_tz":480,"elapsed":32605,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["x_train = []\n","y_train = []\n","# select from github dataset\n","with open(\"memes900k/captions.txt\") as file:\n","  for line in file.readlines():\n","    l,_,text = line.split('\\t')\n","    y_train.append(l.strip())\n","    text = text.strip().replace('<sep>',\"[SEP]\")\n","    x_train.append(text)\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"6EmrQPUX8XUQ","executionInfo":{"status":"ok","timestamp":1604800008722,"user_tz":480,"elapsed":32602,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"9b669bdd-f640-4f37-e46a-93ff13f64bd5","colab":{"base_uri":"https://localhost:8080/"}},"source":["templates_map = dict(zip(set(y_train),range(300)))\n","templates_map_reverse = {v:k for k,v in templates_map.items()}\n","len(templates_map)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"167b3t61GlgC","executionInfo":{"status":"ok","timestamp":1604800008932,"user_tz":480,"elapsed":32806,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["y_train = [templates_map[i] for i in y_train if i ]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Be6ZRy6iVrTS","executionInfo":{"status":"ok","timestamp":1604800008932,"user_tz":480,"elapsed":32803,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["x_test = []\n","y_test = []\n","with open(\"memes900k/captions_test.txt\") as file:\n","  for line in file.readlines():\n","    l,_,text = line.split('\\t')\n","    if l in templates_map:\n","      y_test.append(templates_map[l])\n","      text = text.strip().replace('<sep>',\"[SEP]\")\n","      x_test.append(text)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihsrxjr9SGRe","executionInfo":{"status":"ok","timestamp":1604800008932,"user_tz":480,"elapsed":32799,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"5f8ee753-e6b1-4681-edcd-32e23027b414","colab":{"base_uri":"https://localhost:8080/"}},"source":["len(set(y_train))"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"2iIAaw7I0HXN","executionInfo":{"status":"ok","timestamp":1604800098471,"user_tz":480,"elapsed":122334,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"fc62893a-594d-43ea-c8f4-34ae895c0508","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Tokenize all of the sentences and map the tokens to their word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in x_train:\n","\n","    encoded_dict,attention = prepare_features(sent)\n","    \n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict)\n","    attention_masks.append(torch.Tensor(attention))\n","    \n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', x_train[3])\n","print('Token IDs:', input_ids[3])\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Original:  TED [SEP] y u no tell us how you met their mother\n","Token IDs: tensor([[    3,    17, 19425,  4145,    83,  8186,  3158,    17,   117,    17,\n","           660,   116,   759,   211,   160,    44,  1033,    58,   831,     4]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vjqmTQbltq6C","executionInfo":{"status":"ok","timestamp":1604800099292,"user_tz":480,"elapsed":123151,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["# Convert the lists into tensors.\n","\n","input_ids_t = torch.cat(input_ids, dim=0)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGse8PXkw_kG","executionInfo":{"status":"ok","timestamp":1604800101247,"user_tz":480,"elapsed":125103,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["attention_masks_t = torch.stack(attention_masks, dim=0)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"eupbwl3iC9hx","executionInfo":{"status":"ok","timestamp":1604800101456,"user_tz":480,"elapsed":125309,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["from torch.utils.data import DataLoader, random_split,WeightedRandomSampler, TensorDataset\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","\n","input_train,input_val,label_train,label_val= train_test_split(input_ids_t,torch.tensor(y_train), test_size=0.01)\n","\n","train_dataset = TensorDataset(input_train, label_train)\n","val_dataset = TensorDataset(input_val, label_val)\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"kM0SsPztEwD_","executionInfo":{"status":"ok","timestamp":1604800101457,"user_tz":480,"elapsed":125307,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","\n","batch_size =128\n","\n","\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = 120 # Evaluate with this batch size.\n","        )"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-vopcfvd4yy"},"source":["# Build Model"]},{"cell_type":"code","metadata":{"id":"vC9RIia0aTWb","executionInfo":{"status":"ok","timestamp":1604800101457,"user_tz":480,"elapsed":125305,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","loss_function = nn.CrossEntropyLoss()\n","learning_rate = 1e-03\n","optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5XOUSplVcxX","outputId":"b37f8888-9593-4d46-f1a0-87bcffbe76e8","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ab9e3e9dfa804be193023d8cb842e27e","4a24953540ee45aeb99f6e7e5492b584","37e3f4d646064f2b9fc1ce43b03e21a4","e6a04e4d83ef4252b6428a0a5cd7195f","71cefe6387064158a57c5b3af0f4f454","34ffb6af6aa149d2bc205035d73eb85d","f3db614c47644fef83ac70cb8c5b1f70","1085ae48ce7c48b8984d09feaf10e9bc"]}},"source":["max_epochs = 3\n","model = model.train()\n","for epoch in tqdm_notebook(range(max_epochs)):\n","    print(\"EPOCH -- {}\".format(epoch))\n","    for i, j in enumerate(train_dataloader):\n","        \n","        optimizer.zero_grad()\n","        sent=j[0]\n","        label=j[1]\n","      \n","        sent = sent.squeeze(0)\n","        if torch.cuda.is_available():\n","          sent = sent\n","          label = label\n","\n","        output = model.forward(sent)[0]\n","        _, predicted = torch.max(output, 1)\n","        \n","        loss = loss_function(output, label)\n","        print(\"training\",loss)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if i%100 == 0:\n","            correct = 0\n","            total = 0\n","            for k in validation_dataloader:\n","                sent=k[0]\n","                label=k[1]\n","                sent = sent.squeeze(0)\n","                if torch.cuda.is_available():\n","                  sent = sent\n","                  label = label\n","                output = model.forward(sent)[0]\n","                _, predicted = torch.max(output.data, 1)\n","                total += label.size(0)\n","                correct += (predicted.cpu() == label.cpu()).sum()\n","                print(\"validation\")\n","            accuracy = 100.00 * correct.numpy() / total\n","            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab9e3e9dfa804be193023d8cb842e27e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["EPOCH -- 0\n","training tensor(5.8621, grad_fn=<NllLossBackward>)\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","validation\n","Iteration: 0. Loss: 5.862068176269531. Accuracy: 0.2222222222222222%\n","training tensor(5.7601, grad_fn=<NllLossBackward>)\n","training tensor(6.1821, grad_fn=<NllLossBackward>)\n","training tensor(5.9621, grad_fn=<NllLossBackward>)\n","training tensor(6.0549, grad_fn=<NllLossBackward>)\n","training tensor(6.0761, grad_fn=<NllLossBackward>)\n","training tensor(5.9598, grad_fn=<NllLossBackward>)\n","training tensor(5.8980, grad_fn=<NllLossBackward>)\n","training tensor(5.9489, grad_fn=<NllLossBackward>)\n","training tensor(5.8222, grad_fn=<NllLossBackward>)\n","training tensor(5.8663, grad_fn=<NllLossBackward>)\n","training tensor(5.8513, grad_fn=<NllLossBackward>)\n","training tensor(5.8582, grad_fn=<NllLossBackward>)\n","training tensor(5.8607, grad_fn=<NllLossBackward>)\n","training tensor(5.9122, grad_fn=<NllLossBackward>)\n","training tensor(5.8867, grad_fn=<NllLossBackward>)\n","training tensor(5.9425, grad_fn=<NllLossBackward>)\n","training tensor(5.9029, grad_fn=<NllLossBackward>)\n","training tensor(5.9188, grad_fn=<NllLossBackward>)\n","training tensor(5.9301, grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bz28JmTlFxco","executionInfo":{"status":"error","timestamp":1604810968681,"user_tz":480,"elapsed":752,"user":{"displayName":"Mehak Piplani","photoUrl":"","userId":"04381972525381903232"}},"outputId":"70d0bde5-83a6-46c6-8eb1-a11f2b0b4088","colab":{"base_uri":"https://localhost:8080/","height":162}},"source":["torch.save(model.state_dict(), 'roberat.pth')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-977cd1a1220f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roberat.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"cell_type":"code","metadata":{"id":"jIcELLw6Fbpi","executionInfo":{"status":"ok","timestamp":1604733854454,"user_tz":480,"elapsed":1220,"user":{"displayName":"Che-Pai Kung","photoUrl":"","userId":"03320392365960393515"}},"outputId":"2f844d91-33ce-4d64-84c5-89718bc22515","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=bc.training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>3.09</td>\n","      <td>2.70</td>\n","      <td>0.40</td>\n","      <td>1:44:41</td>\n","      <td>0:03:42</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.49</td>\n","      <td>2.56</td>\n","      <td>0.42</td>\n","      <td>1:44:56</td>\n","      <td>0:03:42</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.11</td>\n","      <td>2.54</td>\n","      <td>0.43</td>\n","      <td>1:44:43</td>\n","      <td>0:03:42</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.74</td>\n","      <td>2.59</td>\n","      <td>0.44</td>\n","      <td>1:44:46</td>\n","      <td>0:03:42</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               3.09         2.70           0.40       1:44:41         0:03:42\n","2               2.49         2.56           0.42       1:44:56         0:03:42\n","3               2.11         2.54           0.43       1:44:43         0:03:42\n","4               1.74         2.59           0.44       1:44:46         0:03:42"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"hhZm83Bqqpyf"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"hej8I6hkHVCi"},"source":["x_test1 = [\"a group of people sitting on a bench\",\"a dog is playing with a toy toy\",\"a cople of women walking down a street\",\"a man riding a wave on top of a surf board\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ns9Kj9Gqruh","executionInfo":{"status":"ok","timestamp":1604737617029,"user_tz":480,"elapsed":863,"user":{"displayName":"Che-Pai Kung","photoUrl":"","userId":"03320392365960393515"}},"outputId":"87ae3dec-ae0a-47ca-9041-e6a83df45ea9","colab":{"base_uri":"https://localhost:8080/"}},"source":["def get_reply(msg):\n","  model.eval()\n","  input_msg, _ = prepare_features(msg)\n","  if torch.cuda.is_available():\n","    input_msg = input_msg\n","  output = model(input_msg)[0]\n","  _, pred_label = torch.max(output.data, 1)\n","  prediction=list(templates_map_reverse.keys())[pred_label]\n","  return prediction"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z-1ke9DQGRuS"},"source":["for i in x_test1:\n","  print(get_reply(i))"],"execution_count":null,"outputs":[]}]}