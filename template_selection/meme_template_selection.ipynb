{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "U1xe-dEUjzyd",
    "outputId": "b6656bd1-5613-4507-e0fb-3ad8e879b895",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L12bijWDkUGr",
    "outputId": "60e1e978-66d6-4f0a-f52c-0da4e5ec1dc6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "cd gdrive/My Drive/memedata/memes900k"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/memedata/memes900k\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lfH1hY1bkpyF",
    "outputId": "a7844b3d-5aad-410c-831a-a47b38fc12d5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "!pip install transformers"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3MB 11.1MB/s \n",
      "\u001B[?25hCollecting tokenizers==0.9.2\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9MB 55.6MB/s \n",
      "\u001B[?25hCollecting sacremoses\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001B[K     |████████████████████████████████| 890kB 53.9MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1MB 46.6MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=ae82aad85940b2cdbcd1d2a38637206f031922cc12aebc7f85c1d01c6c71ccc7\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ruzrr9jpliXI",
    "outputId": "5f37b8d0-6fea-4b65-bf44-cb7ef00459e3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, random_split, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# cd drive/My Drive/CSCI566_project/memes900k\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n",
      "Loading BERT tokenizer...\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ykrursculoxd",
    "outputId": "23f0e2fc-2c42-4d84-f96e-52a628abc894",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "selected = set(['african children dancing', 'Angry Cat Meme', \"Anchorman Birthday\", \"Annoying Gamer Kid\", \"Awkward Seal\",\n",
    "            \"Black Kid\", \"burning house girl\", \"Desk Flip Rage Guy\", \"evil plan kid\", \"FU*CK THAT GUY\", \"Grumpy Cat 2\",\n",
    "            \"Grumpy Cat Santa Hat\", \"high/drunk guy\", \"Joseph Ducreux\", \"Skeptical african kid\", \"so doge\",\n",
    "            \"Success Kid\", \"Willy Wonka\", \"You shall not pass\", \"Y U No\"])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "# select from github dataset\n",
    "with open(\"captions_train.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        l, _, text = line.split('\\t')\n",
    "        if l.strip() in selected:\n",
    "            y_train.append(l.strip())\n",
    "            text = text.strip().replace('<sep>', \", \")\n",
    "            x_train.append(text)\n",
    "# x_train = x_train[:5000]\n",
    "# y_train = y_train[:5000]\n",
    "\n",
    "# select from https://imgflip.com/memetemplates\n",
    "# with open(\"memes_output.txt\") as file:\n",
    "#     for line in file.readlines():\n",
    "#         l, _, text = line.split('\\t')\n",
    "#         y_train.append(l.strip())\n",
    "#         text = text.strip().replace(';', \"[SEP]\")\n",
    "#         x_train.append(text)\n",
    "\n",
    "templates_map = dict(zip(set(y_train), range(300)))\n",
    "templates_map_reverse = dict(zip(range(300), set(y_train)))\n",
    "len(templates_map)\n",
    "\n",
    "y_train = [templates_map[i] for i in y_train if i]\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "with open(\"captions_test.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        l, _, text = line.split('\\t')\n",
    "        if l in templates_map:\n",
    "            y_test.append(templates_map[l])\n",
    "            text = text.strip().replace('<sep>', \", \")\n",
    "            # text = text.strip()\n",
    "            x_test.append(text)\n",
    "\n",
    "set(y_test)\n",
    "# x_test = x_test[:2500]\n",
    "# y_test = y_test[:2500]\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "with open(\"captions_val.txt\") as file:\n",
    "    for line in file.readlines():\n",
    "        l, _, text = line.split('\\t')\n",
    "        if l in templates_map:\n",
    "            y_val.append(templates_map[l])\n",
    "            text = text.strip().replace('<sep>', \", \")\n",
    "            # text = text.strip()\n",
    "            x_val.append(text)\n",
    "# x_val = x_val[:1000]\n",
    "# y_val = y_val[:1000]\n",
    "set(y_val)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in x_train:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=50,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "input_vals = []\n",
    "attention_masks_val = []\n",
    "# For every sentence...\n",
    "for sent in x_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=50,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_vals.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_val.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_vals = torch.cat(input_vals, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "\n",
    "print('Original: ', x_train[3])\n",
    "print('Token IDs:', input_ids[3])\n",
    "\n",
    "# Create a 85-15 train-validation split proportional to number of classes.\n",
    "\n",
    "# input_train,input_val,mask_train,mask_val,label_train,label_val = train_test_split(input_ids, attention_masks, torch.tensor(y_train), test_size=0.15, stratify=torch.tensor(y_train))\n",
    "# train_dataset = TensorDataset(input_train, mask_train, label_train)\n",
    "# val_dataset = TensorDataset(input_val, mask_val, label_val)\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, torch.tensor(y_train))\n",
    "val_dataset = TensorDataset(input_vals, attention_masks_val, torch.tensor(y_val))\n",
    "# Checking whether the distribution of target is consitent across both the sets\n",
    "label_temp_list = []\n",
    "for a, b, c in train_dataset:\n",
    "    label_temp_list.append(c)\n",
    "\n",
    "# print('{:>5,} training samples'.format(train_size))\n",
    "print(Counter(list(map(int, label_temp_list))))\n",
    "\n",
    "label_temp_list = []\n",
    "for a, b, c in val_dataset:\n",
    "    label_temp_list.append(c)\n",
    "\n",
    "# print('{:>5,} validation samples'.format(val_size))\n",
    "print(Counter(list(map(int, label_temp_list))))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,  # The training samples.\n",
    "    sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
    "    batch_size=batch_size  # Trains with this batch size.\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,  # The validation samples.\n",
    "    sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
    "    batch_size=batch_size  # Evaluate with this batch size.\n",
    ")"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Original:  universal remote ,  y u no work on universe?\n",
      "Token IDs: tensor([ 101, 5415, 6556, 1010, 1061, 1057, 2053, 2147, 2006, 5304, 1029,  102,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n",
      "Counter({13: 2500, 0: 2500, 9: 2500, 6: 2500, 19: 2500, 7: 2500, 5: 2500, 17: 2500, 14: 2500, 18: 2500, 2: 2500, 8: 2500, 10: 2500, 4: 2500, 3: 2500, 16: 2500, 11: 2500, 12: 2500, 1: 2500, 15: 2500})\n",
      "Counter({13: 250, 0: 250, 9: 250, 6: 250, 19: 250, 7: 250, 17: 250, 14: 250, 18: 250, 2: 250, 8: 250, 10: 250, 4: 250, 3: 250, 16: 250, 11: 250, 12: 250, 1: 250, 15: 250})\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aj0jrWqtiTIr"
   },
   "source": [
    "\n",
    "\n",
    "# # Build Model\n",
    "\n",
    "class BertClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\n",
    "            \"bert-base-uncased\",\n",
    "            num_labels=num_labels,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "\n",
    "    def flat_accuracy(self, preds, labels):\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        labels_flat = labels.flatten()\n",
    "        return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "    def format_time(self, elapsed):\n",
    "        '''\n",
    "        Takes a time in seconds and returns a string hh:mm:ss\n",
    "        '''\n",
    "        # Round to the nearest second.\n",
    "        elapsed_rounded = int(round((elapsed)))\n",
    "        # Format as hh:mm:ss\n",
    "        return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "    def train(self, train_dataloader, validation_dataloader, epochs=4):\n",
    "        self.model.cuda()\n",
    "        optimizer = AdamW(self.model.parameters(),\n",
    "                          lr=7e-5,  # args.learning_rate - default is 5e-5\n",
    "                          eps=2e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                          )\n",
    "        total_steps = len(train_dataloader) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=0,\n",
    "                                                    num_training_steps=total_steps)\n",
    "\n",
    "        seed_val = 66\n",
    "        random.seed(seed_val)\n",
    "        np.random.seed(seed_val)\n",
    "        torch.manual_seed(seed_val)\n",
    "        torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "        self.training_stats = []\n",
    "\n",
    "        total_t0 = time.time()\n",
    "\n",
    "        for epoch_i in range(0, epochs):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            self.model.train()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "                # Progress update every 40 batches.\n",
    "                if step % 40 == 0 and not step == 0:\n",
    "                    # Calculate elapsed time in minutes.\n",
    "                    elapsed = self.format_time(time.time() - t0)\n",
    "\n",
    "                    # Report progress.\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_input_mask = batch[1].to(device)\n",
    "                b_labels = batch[2].to(device)\n",
    "\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                loss, logits = self.model(b_input_ids,\n",
    "                                          token_type_ids=None,\n",
    "                                          attention_mask=b_input_mask,\n",
    "                                          labels=b_labels)\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "                # Perform a backward pass to calculate the gradients.\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "            # Measure how long this epoch took.\n",
    "            training_time = self.format_time(time.time() - t0)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "            print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "\n",
    "            # Validation\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\")\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Put the model in evaluation mode\n",
    "            self.model.eval()\n",
    "\n",
    "            # Tracking variables\n",
    "            total_eval_accuracy = 0\n",
    "            total_eval_loss = 0\n",
    "            nb_eval_steps = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in validation_dataloader:\n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_input_mask = batch[1].to(device)\n",
    "                b_labels = batch[2].to(device)\n",
    "\n",
    "                # Tell pytorch not to bother with constructing the compute graph during\n",
    "                # the forward pass, since this is only needed for backprop (training).\n",
    "                with torch.no_grad():\n",
    "                    (loss, logits) = self.model(b_input_ids,\n",
    "                                                token_type_ids=None,\n",
    "                                                attention_mask=b_input_mask,\n",
    "                                                labels=b_labels)\n",
    "\n",
    "                # Accumulate the validation loss.\n",
    "                total_eval_loss += loss.item()\n",
    "\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "                # Calculate the accuracy for this batch of test sentences, and\n",
    "                # accumulate it over all batches.\n",
    "                total_eval_accuracy += self.flat_accuracy(logits, label_ids)\n",
    "\n",
    "            avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "            print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "            avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "            validation_time = self.format_time(time.time() - t0)\n",
    "\n",
    "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "            # Record all statistics from this epoch.\n",
    "            self.training_stats.append(\n",
    "                {\n",
    "                    'epoch': epoch_i + 1,\n",
    "                    'Training Loss': avg_train_loss,\n",
    "                    'Valid. Loss': avg_val_loss,\n",
    "                    'Valid. Accur.': avg_val_accuracy,\n",
    "                    'Training Time': training_time,\n",
    "                    'Validation Time': validation_time\n",
    "                }\n",
    "            )\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Training complete!\")\n",
    "        print(\"Total training took {:} (h:mm:ss)\".format(self.format_time(time.time() - total_t0)))\n",
    "\n",
    "    def predict(self, validation_dataloader):\n",
    "        print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Tracking variables\n",
    "        self.predictions = []\n",
    "\n",
    "        # Predict\n",
    "        for batch in validation_dataloader:\n",
    "            # Add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            b_input_ids, b_input_mask, _ = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(b_input_ids, token_type_ids=None,\n",
    "                                     attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            # label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            self.predictions.append(logits)\n",
    "\n",
    "        print('    DONE.')"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s1gbB7NGlYu3",
    "outputId": "1d170cec-26bb-40dd-f8e6-fc91a903c2ae",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "bc = BertClassification(25)\n",
    "bc.train(train_dataloader, validation_dataloader, 2)\n",
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(bc.model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "df_stats = pd.DataFrame(data=bc.training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()\n"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,563.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  1,563.    Elapsed: 0:00:24.\n",
      "  Batch   120  of  1,563.    Elapsed: 0:00:37.\n",
      "  Batch   160  of  1,563.    Elapsed: 0:00:49.\n",
      "  Batch   200  of  1,563.    Elapsed: 0:01:02.\n",
      "  Batch   240  of  1,563.    Elapsed: 0:01:14.\n",
      "  Batch   280  of  1,563.    Elapsed: 0:01:26.\n",
      "  Batch   320  of  1,563.    Elapsed: 0:01:38.\n",
      "  Batch   360  of  1,563.    Elapsed: 0:01:51.\n",
      "  Batch   400  of  1,563.    Elapsed: 0:02:03.\n",
      "  Batch   440  of  1,563.    Elapsed: 0:02:15.\n",
      "  Batch   480  of  1,563.    Elapsed: 0:02:28.\n",
      "  Batch   520  of  1,563.    Elapsed: 0:02:40.\n",
      "  Batch   560  of  1,563.    Elapsed: 0:02:52.\n",
      "  Batch   600  of  1,563.    Elapsed: 0:03:05.\n",
      "  Batch   640  of  1,563.    Elapsed: 0:03:17.\n",
      "  Batch   680  of  1,563.    Elapsed: 0:03:29.\n",
      "  Batch   720  of  1,563.    Elapsed: 0:03:42.\n",
      "  Batch   760  of  1,563.    Elapsed: 0:03:54.\n",
      "  Batch   800  of  1,563.    Elapsed: 0:04:06.\n",
      "  Batch   840  of  1,563.    Elapsed: 0:04:19.\n",
      "  Batch   880  of  1,563.    Elapsed: 0:04:31.\n",
      "  Batch   920  of  1,563.    Elapsed: 0:04:43.\n",
      "  Batch   960  of  1,563.    Elapsed: 0:04:55.\n",
      "  Batch 1,000  of  1,563.    Elapsed: 0:05:08.\n",
      "  Batch 1,040  of  1,563.    Elapsed: 0:05:20.\n",
      "  Batch 1,080  of  1,563.    Elapsed: 0:05:32.\n",
      "  Batch 1,120  of  1,563.    Elapsed: 0:05:44.\n",
      "  Batch 1,160  of  1,563.    Elapsed: 0:05:57.\n",
      "  Batch 1,200  of  1,563.    Elapsed: 0:06:09.\n",
      "  Batch 1,240  of  1,563.    Elapsed: 0:06:21.\n",
      "  Batch 1,280  of  1,563.    Elapsed: 0:06:34.\n",
      "  Batch 1,320  of  1,563.    Elapsed: 0:06:46.\n",
      "  Batch 1,360  of  1,563.    Elapsed: 0:06:58.\n",
      "  Batch 1,400  of  1,563.    Elapsed: 0:07:11.\n",
      "  Batch 1,440  of  1,563.    Elapsed: 0:07:23.\n",
      "  Batch 1,480  of  1,563.    Elapsed: 0:07:35.\n",
      "  Batch 1,520  of  1,563.    Elapsed: 0:07:47.\n",
      "  Batch 1,560  of  1,563.    Elapsed: 0:08:00.\n",
      "\n",
      "  Average training loss: 1.44\n",
      "  Training epcoh took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 1.21\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,563.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  1,563.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  1,563.    Elapsed: 0:00:37.\n",
      "  Batch   160  of  1,563.    Elapsed: 0:00:49.\n",
      "  Batch   200  of  1,563.    Elapsed: 0:01:01.\n",
      "  Batch   240  of  1,563.    Elapsed: 0:01:14.\n",
      "  Batch   280  of  1,563.    Elapsed: 0:01:26.\n",
      "  Batch   320  of  1,563.    Elapsed: 0:01:38.\n",
      "  Batch   360  of  1,563.    Elapsed: 0:01:51.\n",
      "  Batch   400  of  1,563.    Elapsed: 0:02:03.\n",
      "  Batch   440  of  1,563.    Elapsed: 0:02:15.\n",
      "  Batch   480  of  1,563.    Elapsed: 0:02:27.\n",
      "  Batch   520  of  1,563.    Elapsed: 0:02:40.\n",
      "  Batch   560  of  1,563.    Elapsed: 0:02:52.\n",
      "  Batch   600  of  1,563.    Elapsed: 0:03:04.\n",
      "  Batch   640  of  1,563.    Elapsed: 0:03:17.\n",
      "  Batch   680  of  1,563.    Elapsed: 0:03:29.\n",
      "  Batch   720  of  1,563.    Elapsed: 0:03:41.\n",
      "  Batch   760  of  1,563.    Elapsed: 0:03:53.\n",
      "  Batch   800  of  1,563.    Elapsed: 0:04:06.\n",
      "  Batch   840  of  1,563.    Elapsed: 0:04:18.\n",
      "  Batch   880  of  1,563.    Elapsed: 0:04:30.\n",
      "  Batch   920  of  1,563.    Elapsed: 0:04:43.\n",
      "  Batch   960  of  1,563.    Elapsed: 0:04:55.\n",
      "  Batch 1,000  of  1,563.    Elapsed: 0:05:07.\n",
      "  Batch 1,040  of  1,563.    Elapsed: 0:05:19.\n",
      "  Batch 1,080  of  1,563.    Elapsed: 0:05:32.\n",
      "  Batch 1,120  of  1,563.    Elapsed: 0:05:44.\n",
      "  Batch 1,160  of  1,563.    Elapsed: 0:05:56.\n",
      "  Batch 1,200  of  1,563.    Elapsed: 0:06:09.\n",
      "  Batch 1,240  of  1,563.    Elapsed: 0:06:21.\n",
      "  Batch 1,280  of  1,563.    Elapsed: 0:06:33.\n",
      "  Batch 1,320  of  1,563.    Elapsed: 0:06:45.\n",
      "  Batch 1,360  of  1,563.    Elapsed: 0:06:58.\n",
      "  Batch 1,400  of  1,563.    Elapsed: 0:07:10.\n",
      "  Batch 1,440  of  1,563.    Elapsed: 0:07:22.\n",
      "  Batch 1,480  of  1,563.    Elapsed: 0:07:34.\n",
      "  Batch 1,520  of  1,563.    Elapsed: 0:07:47.\n",
      "  Batch 1,560  of  1,563.    Elapsed: 0:07:59.\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:08:00\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 1.16\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:16:30 (h:mm:ss)\n",
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                          (25, 768)\n",
      "classifier.bias                                                (25,)\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gs-jg76ilReQ",
    "outputId": "bcf0f149-a2c2-4cd0-d845-1031e8300fef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    }
   },
   "source": [
    "# # Predict\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in x_test:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=50,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "    )\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "# labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, torch.tensor(y_test))\n",
    "# prediction_data = TensorDataset(input_ids, attention_masks)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "bc.predict(prediction_dataloader)\n",
    "\n",
    "prediction_label = []\n",
    "for p in bc.predictions:\n",
    "    prediction_label.extend(p.argmax(axis=1))\n",
    "\n",
    "f1_score(y_test, prediction_label, average='weighted')"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Predicting labels for 4,750 test sentences...\n",
      "    DONE.\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-39-fd623e333a17>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0mf1_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprediction_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maverage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'weighted'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprediction_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maverage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'weighted'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: accuracy_score() got an unexpected keyword argument 'average'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_score(y_test, prediction_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, prediction_label, average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Km8whS8_2-8x",
    "outputId": "7b2f2e30-f8c8-406d-9e17-1224196ae048",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "\n",
    "# test_sent = \"eating dinner with a friend's family, family leaves for a few minutes\"\n",
    "# test_sent = \"at a sleepover in a friend's house first one to wake up\"\n",
    "test_sent = \"i am not angry i'm happiness challenged\"\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "        test_sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=50,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "    )\n",
    "test_single = TensorDataset(torch.cat([encoded_dict['input_ids']], dim=0),torch.cat([encoded_dict['attention_mask']], dim=0),torch.tensor([1]))\n",
    "loader_data = DataLoader(test_single)\n",
    "bc.predict(loader_data)\n",
    "prediction_label = []\n",
    "for p in bc.predictions:\n",
    "    print(templates_map_reverse[p.argmax(axis=1)[0]])"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6381052631578947"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 40
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tUnWZLgc3EU6",
    "outputId": "9321f87d-2cf2-40da-89f1-2f787988c538",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, prediction_label, average='weighted')"
   ],
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.645603938097743"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 42
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MW_apjcwsmxL",
    "outputId": "14699f5f-cf8a-4d8b-e925-5af03640c302",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "\n",
    "# test_sent = \"eating dinner with a friend's family, family leaves for a few minutes\"\n",
    "# test_sent = \"at a sleepover in a friend's house first one to wake up\"\n",
    "test_sent = \"i am not angry i'm happiness challenged\"\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "        test_sent,  # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=50,  # Pad & truncate all sentences.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Construct attn. masks.\n",
    "        return_tensors='pt',  # Return pytorch tensors.\n",
    "    )\n",
    "test_single = TensorDataset(torch.cat([encoded_dict['input_ids']], dim=0),torch.cat([encoded_dict['attention_mask']], dim=0),torch.tensor([1]))\n",
    "loader_data = DataLoader(test_single)\n",
    "bc.predict(loader_data)\n",
    "prediction_label = []\n",
    "for p in bc.predictions:\n",
    "    print(templates_map_reverse[p.argmax(axis=1)[0]])"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Predicting labels for 4,750 test sentences...\n",
      "    DONE.\n",
      "Grumpy Cat 2\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9r8E55tyx-_j",
    "outputId": "26ef32df-8f0c-4ef1-d719-58ebf68f407c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(len(selected))"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "20\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}